@book{the_turing_way_community_2021,
  author       = {{The Turing Way Community}},
  title        = {{The Turing Way: A handbook for reproducible, ethical and collaborative research}},
  month        = nov,
  year         = 2021,
  publisher    = {Zenodo},
  version      = {1.0.1},
  doi          = {10.5281/zenodo.5671094},
}

@book{markowetz_2015,
	title = {Five selfish reasons to work reproducibly},
	volume = {16},
	doi = {10.1186/s13059-015-0850-7},
	abstract = {And so, my fellow scientists: ask not what you can do for reproducibility; ask what reproducibility can do for you! Here, I present five reasons why working reproducibly pays off in the long run and is in the self-interest of every ambitious, career-oriented scientist.},
	number = {1},
	journal = {Genome Biology},
	author = {Markowetz, Florian},
	month = dec,
	year = {2015},
	pages = {274},
}


@book{nuijten_2016,
	title = {The prevalence of statistical reporting errors in psychology (1985-2013)},
	volume = {48},
	doi = {10.3758/s13428-015-0664-2},
	abstract = {This study documents reporting errors in a sample of over 250,000 p-values reported in eight major psychology journals from 1985 until 2013, using the new R package “statcheck.” statcheck retrieved null-hypothesis significance testing (NHST) results from over half of the articles from this period. In line with earlier research, we found that half of all published psychology papers that use NHST contained at least one p-value that was inconsistent with its test statistic and degrees of freedom. One in eight papers contained a grossly inconsistent p-value that may have affected the statistical conclusion. In contrast to earlier findings, we found that the average prevalence of inconsistent p-values has been stable over the years or has declined. The prevalence of gross inconsistencies was higher in p-values reported as significant than in p-values reported as nonsignificant. This could indicate a systematic bias in favor of significant results. Possible solutions for the high prevalence of reporting inconsistencies could be to encourage sharing data, to let co-authors check results in a so-called “co-pilot model,” and to use statcheck to flag possible inconsistencies in one’s own manuscript or during the review process.},
	number = {4},
	journal = {Behavior Research Methods},
	author = {Nuijten, Michèle B. and Hartgerink, Chris H. J. and van Assen, Marcel A. L. M. and Epskamp, Sacha and Wicherts, Jelte M.},
	month = dec,
	year = {2016},
	pages = {1205--1226},
}

@book{ziemann_2016,
	title = {Gene name errors are widespread in the scientific literature},
	volume = {17},
	doi = {10.1186/s13059-016-1044-7},
	abstract = {The spreadsheet software Microsoft Excel, when used with default settings, is known to convert gene names to dates and floating-point numbers. A programmatic scan of leading genomics journals reveals that approximately one-fifth of papers with supplementary Excel gene lists contain erroneous gene name conversions.},
	number = {1},
	journal = {Genome Biology},
	author = {Ziemann, Mark and Eren, Yotam and El-Osta, Assam},
	month = aug,
	year = {2016},
	pages = {177},
}